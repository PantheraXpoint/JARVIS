[
  {
    "role": "user",
    "content_array": [
      "Below is an example demonstrating how to construct a task pipeline from a scenario description.",
      "",
      "**UNDERSTANDING THE INPUT FORMAT (Scenario)**:",
      "",
      "The scenario has 2 key fields:",
      "",
      "1. **objects-seen** (array of strings): Lists all object types visible in the scene.",
      "   - Purpose: Tells you WHAT objects are present so you know which detection/classification tasks are applicable",
      "   - Example: [\"car\", \"truck\", \"person\"] means the scene contains vehicles and people",
      "   - How it guides task selection: If \"person\" is present → you can use person-related tasks (face-detection, cloth-color-classification, human-pose-detection)",
      "   - How it guides task selection: If vehicles are present → you can use vehicle-related tasks (vehicle-color-classification, vehicle-make-classification)",
      "",
      "2. **sample-description** (string): A detailed narrative description of the scene and what's happening.",
      "   - Purpose: Provides CONTEXT about the situation - is it normal, emergency, accident, etc.",
      "   - Example: \"A fire is burning\" → indicates emergency, you should include fire-detection",
      "   - Example: \"People engaged in physical altercation\" → indicates a fight, you may exclude emotion-classification (unreliable in conflict)",
      "   - Example: \"Person lying motionless on ground\" → indicates potential injury, you should include human-pose-detection",
      "   - How it guides task selection: The context determines which tasks are relevant and which should be excluded",
      "",
      "**UNDERSTANDING THE OUTPUT FORMAT (Tasks)**:",
      "",
      "Each task in the pipeline has exactly 6 required fields:",
      "",
      "1. **id** (string): The task type identifier from the available task list",
      "   - Must be one of the task IDs from AVAILABLE TASK TYPES",
      "   - Examples: \"source\", \"object-detection-general\", \"face-detection\", \"pipeline-end\"",
      "",
      "2. **inputs_from_upstreams** (array of strings): Semantic description of what data this task receives as input",
      "   - Describes WHAT data flows into this task",
      "   - Must match the \"outputs_for_downstreams\" of upstream tasks",
      "   - Examples: [\"none\"] for source, [\"image\"] for first processing task, [\"person bounding boxes\"] for face-detection",
      "",
      "3. **upstreams** (array of strings): List of task IDs that must complete BEFORE this task can run",
      "   - Defines WHICH tasks this task depends on",
      "   - Determines execution order in the DAG",
      "   - Examples: [\"none\"] for source, [\"source\"] for object-detection-general, [\"object-detection-general\"] for face-detection",
      "",
      "4. **outputs_for_downstreams** (array of strings): Semantic description of what data this task produces",
      "   - Describes WHAT data flows out of this task",
      "   - Must match the \"inputs_from_upstreams\" of downstream tasks",
      "   - Examples: [\"image\"] for source, [\"bounding boxes\"] for object-detection-general, [\"face bounding boxes\"] for face-detection",
      "",
      "5. **downstreams** (array of strings): List of task IDs that will run AFTER this task completes",
      "   - Defines WHICH tasks depend on this task's output",
      "   - Determines execution flow in the DAG",
      "   - Examples: [\"object-detection-general\"] for source, [\"gender-classification\", \"face-recognition\"] for face-detection",
      "",
      "6. **sample-reasoning** (array of strings): Explanations for task selection and dependency decisions",
      "   - Explains WHY downstream tasks were chosen",
      "   - Explains WHY some tasks were NOT chosen (especially in special scenarios)",
      "   - Provides context from the scenario description",
      "   - This field is for learning/understanding only - NOT included in your final output",
      "",
      "**NOW HERE'S AN EXAMPLE**:",
      "",
      "Scenario:",
      "objects-seen: [\"car\", \"truck\", \"bus\", \"motorcycle\", \"bicycle\", \"person\"]",
      "sample-description: \"In a typical urban intersection, a crowd of people is gathered around a car, with some individuals appearing to be in a physical altercation. The car is parked on the side of the road, and several people are standing close to it, interacting with each other. Vehicles, including cars and trucks, are moving through the intersection at a moderate pace, and pedestrians are crossing at designated crosswalks.\"",
      "",
      "**ANALYSIS OF THIS SCENARIO**:",
      "- Objects present: Both vehicles (car, truck, bus, motorcycle, bicycle) AND people",
      "- Context: Physical altercation happening (fight scenario)",
      "- Key observations:",
      "  * People are in conflict → human-pose-detection NOT reliable during fights (excluded)",
      "  * People are in conflict → emotion-classification NOT reliable during fights (excluded)",
      "  * Vehicles present but not primary focus → still analyze for context (vehicle-color, vehicle-make, vehicle-plate)",
      "  * People present and central to incident → face-detection, gender-classification, face-recognition (for identification)",
      "  * People present → cloth-color-classification (helps identification)",
      "",
      "Expected output (showing how scenario leads to task pipeline):"
    ]
  },
  {
    "role": "assistant",
    "content_array": [
      "[",
      "  {",
      "    \"id\": \"source\",",
      "    \"inputs_from_upstreams\": [\"none\"],",
      "    \"upstreams\": [\"none\"],",
      "    \"outputs_for_downstreams\": [\"image\"],",
      "    \"downstreams\": [\"object-detection-general\"],",
      "    \"sample-reasoning\": [",
      "      \"object-detection-general: From objects-seen field, we know both vehicles and people are present, so we need general object detection as the first processing step\"",
      "    ]",
      "  },",
      "  {",
      "    \"id\": \"object-detection-general\",",
      "    \"inputs_from_upstreams\": [\"image\"],",
      "    \"upstreams\": [\"source\"],",
      "    \"outputs_for_downstreams\": [\"bounding boxes\"],",
      "    \"downstreams\": [",
      "      \"vehicle-color-classification\",",
      "      \"vehicle-make-classification\",",
      "      \"cloth-color-classification\"",
      "    ],",
      "    \"sample-reasoning\": [",
      "      \"vehicle-color-classification: From objects-seen field [car, truck, bus, motorcycle, bicycle], vehicles are present → classify their colors for identification\",",
      "      \"vehicle-make-classification: From objects-seen field [car, truck, bus, motorcycle, bicycle], vehicles are present → identify makes for identification\",",
      "      \"cloth-color-classification: From objects-seen field [person], people are present → classify clothing for identification\",",
      "      \"human-pose-detection: EXCLUDED - sample-description mentions 'physical altercation', pose detection is unreliable during fights\"",
      "    ]",
      "  },",
      "  {",
      "    \"id\": \"vehicle-color-classification\",",
      "    \"inputs_from_upstreams\": [\"vehicle bounding boxes\"],",
      "    \"upstreams\": [\"object-detection-general\"],",
      "    \"outputs_for_downstreams\": [\"vehicle color labels\"],",
      "    \"downstreams\": [\"pipeline-end\"],",
      "    \"sample-reasoning\": [",
      "      \"pipeline-end: This is a terminal task (no other tasks need its output), so it connects directly to pipeline-end\"",
      "    ]",
      "  },",
      "  {",
      "    \"id\": \"vehicle-make-classification\",",
      "    \"inputs_from_upstreams\": [\"vehicle bounding boxes\"],",
      "    \"upstreams\": [\"object-detection-general\"],",
      "    \"outputs_for_downstreams\": [\"vehicle make labels\"],",
      "    \"downstreams\": [\"vehicle-plate-detection\"],",
      "    \"sample-reasoning\": [",
      "      \"vehicle-plate-detection: Sequential dependency - knowing vehicle make helps accurately locate license plates (make info guides plate detection)\"",
      "    ]",
      "  },",
      "  {",
      "    \"id\": \"vehicle-plate-detection\",",
      "    \"inputs_from_upstreams\": [\"vehicle bounding boxes\"],",
      "    \"upstreams\": [\"vehicle-make-classification\"],",
      "    \"outputs_for_downstreams\": [\"license plate bounding boxes\"],",
      "    \"downstreams\": [\"pipeline-end\"],",
      "    \"sample-reasoning\": [",
      "      \"pipeline-end: This is a terminal task, connects to pipeline-end\"",
      "    ]",
      "  },",
      "  {",
      "    \"id\": \"cloth-color-classification\",",
      "    \"inputs_from_upstreams\": [\"person bounding boxes\"],",
      "    \"upstreams\": [\"object-detection-general\"],",
      "    \"outputs_for_downstreams\": [\"cloth color labels\"],",
      "    \"downstreams\": [\"face-detection\"],",
      "    \"sample-reasoning\": [",
      "      \"face-detection: Sequential dependency - sample-description mentions 'physical altercation', need face detection for identifying individuals involved\"",
      "    ]",
      "  },",
      "  {",
      "    \"id\": \"face-detection\",",
      "    \"inputs_from_upstreams\": [\"person bounding boxes\"],",
      "    \"upstreams\": [\"cloth-color-classification\"],",
      "    \"outputs_for_downstreams\": [\"face bounding boxes\"],",
      "    \"downstreams\": [\"gender-classification\", \"face-recognition\"],",
      "    \"sample-reasoning\": [",
      "      \"gender-classification: Sample-description mentions altercation, identifying gender helps with identification and incident documentation\",",
      "      \"face-recognition: Sample-description mentions altercation, face recognition crucial for identifying individuals involved\",",
      "      \"emotion-classification: EXCLUDED - sample-description mentions 'physical altercation', emotion classification unreliable during fights/conflict\"",
      "    ]",
      "  },",
      "  {",
      "    \"id\": \"gender-classification\",",
      "    \"inputs_from_upstreams\": [\"face bounding boxes\"],",
      "    \"upstreams\": [\"face-detection\"],",
      "    \"outputs_for_downstreams\": [\"gender labels\"],",
      "    \"downstreams\": [\"pipeline-end\"],",
      "    \"sample-reasoning\": [",
      "      \"pipeline-end: This is a terminal task, connects to pipeline-end\"",
      "    ]",
      "  },",
      "  {",
      "    \"id\": \"face-recognition\",",
      "    \"inputs_from_upstreams\": [\"face bounding boxes\"],",
      "    \"upstreams\": [\"face-detection\"],",
      "    \"outputs_for_downstreams\": [\"identity labels\"],",
      "    \"downstreams\": [\"pipeline-end\"],",
      "    \"sample-reasoning\": [",
      "      \"pipeline-end: This is a terminal task, connects to pipeline-end\"",
      "    ]",
      "  },",
      "  {",
      "    \"id\": \"pipeline-end\",",
      "    \"inputs_from_upstreams\": [\"various task outputs\"],",
      "    \"upstreams\": [",
      "      \"vehicle-color-classification\",",
      "      \"vehicle-plate-detection\",",
      "      \"gender-classification\",",
      "      \"face-recognition\"",
      "    ],",
      "    \"outputs_for_downstreams\": [\"none\"],",
      "    \"downstreams\": [],",
      "    \"sample-reasoning\": []",
      "  }",
      "]"
    ]
  }
]
