{
  "tasks": [
    {
      "id": "source",
      "model_id": "none",
      "inputs_from_upstreams": [
        "none"
      ],
      "upstreams": [
        "none"
      ],
      "outputs_for_downstreams": [
        "image"
      ],
      "downstreams": [
        "object-detection-general"
      ],
      "model-chosen-reason": "Source task doesn't need a model",
      "sample-reasoning": {
        "object-detection-general": "Since the scenario mentions a person lying face down on the ground, detecting objects in the scene is crucial for identifying the person and other relevant elements, such as vehicles and passersby, for safety and emergency response."
      }
    },
    {
      "id": "object-detection-general",
      "model_id": "yolov5m",
      "inputs_from_upstreams": [
        "image"
      ],
      "upstreams": [
        "source"
      ],
      "outputs_for_downstreams": [
        "bounding boxes"
      ],
      "downstreams": [
        "face-detection",
        "cloth-color-classification",
        "human-pose-detection"
      ],
      "model-chosen-reason": "YOLOv5m provides a good balance of speed and accuracy for detecting objects in the scene, including people, vehicles, and other relevant elements.",
      "sample-reasoning": {
        "face-detection": "Since the scenario involves a person lying face down, detecting faces is important for identifying the individual and assessing their condition.",
        "cloth-color-classification": "Since the scenario mentions passersby, classifying clothing colors can help in recognizing and identifying individuals.",
        "human-pose-detection": "Since the scenario involves a person lying face down, detecting the human pose is crucial to understand the person's position and assess their condition."
      }
    },
    {
      "id": "face-detection",
      "model_id": "retina1face",
      "inputs_from_upstreams": [
        "person bounding boxes"
      ],
      "upstreams": [
        "object-detection-general"
      ],
      "outputs_for_downstreams": [
        "face bounding boxes"
      ],
      "downstreams": [
        "gender-classification",
        "emotion-classification",
        "face-recognition"
      ],
      "model-chosen-reason": "RetinaFace on bounding boxes is optimized for efficient face detection within specified bounding boxes, making it suitable for identifying faces in the scene.",
      "sample-reasoning": {
        "gender-classification": "Since the scenario involves a person lying face down, determining gender is important for assessing the individual's identity and condition.",
        "emotion-classification": "Since the scenario mentions passersby, analyzing facial expressions can help in understanding the emotional state of the individuals.",
        "face-recognition": "Since the scenario involves a person lying face down, identifying the individual is crucial for emergency response and safety measures."
      }
    },
    {
      "id": "gender-classification",
      "model_id": "gender",
      "inputs_from_upstreams": [
        "face bounding boxes"
      ],
      "upstreams": [
        "face-detection"
      ],
      "outputs_for_downstreams": [
        "gender labels"
      ],
      "downstreams": [
        "pipeline-end"
      ],
      "model-chosen-reason": "Gender Classifier is specifically trained to classify and identify gender of faces in images, making it suitable for the scenario.",
      "sample-reasoning": {
        "pipeline-end": "Finalizing the pipeline after analysis."
      }
    },
    {
      "id": "emotion-classification",
      "model_id": "emotion",
      "inputs_from_upstreams": [
        "face bounding boxes"
      ],
      "upstreams": [
        "face-detection"
      ],
      "outputs_for_downstreams": [
        "emotion labels"
      ],
      "downstreams": [
        "pipeline-end"
      ],
      "model-chosen-reason": "Emotion Classifier is specifically trained to classify and identify emotions of faces in images, making it suitable for the scenario.",
      "sample-reasoning": {
        "pipeline-end": "Finalizing the pipeline after analysis."
      }
    },
    {
      "id": "face-recognition",
      "model_id": "arcface",
      "inputs_from_upstreams": [
        "face bounding boxes"
      ],
      "upstreams": [
        "face-detection"
      ],
      "outputs_for_downstreams": [
        "identity labels"
      ],
      "downstreams": [
        "pipeline-end"
      ],
      "model-chosen-reason": "ArcFace is a state-of-the-art face recognition model that accurately identifies and verifies faces in images, making it suitable for the scenario.",
      "sample-reasoning": {
        "pipeline-end": "Finalizing the pipeline after analysis."
      }
    },
    {
      "id": "cloth-color-classification",
      "model_id": "fashioncolor",
      "inputs_from_upstreams": [
        "person bounding boxes"
      ],
      "upstreams": [
        "object-detection-general"
      ],
      "outputs_for_downstreams": [
        "cloth color labels"
      ],
      "downstreams": [
        "pipeline-end"
      ],
      "model-chosen-reason": "Cloth Color Classifier is specifically trained to classify and identify colors in clothing items, making it suitable for the scenario.",
      "sample-reasoning": {
        "pipeline-end": "Finalizing the pipeline after analysis."
      }
    },
    {
      "id": "human-pose-detection",
      "model_id": "movenet",
      "inputs_from_upstreams": [
        "person bounding boxes"
      ],
      "upstreams": [
        "object-detection-general"
      ],
      "outputs_for_downstreams": [
        "pose key points"
      ],
      "downstreams": [
        "pipeline-end"
      ],
      "model-chosen-reason": "MoveNet is a fast and accurate pose detection model that identifies key points of the human body in images, making it suitable for the scenario.",
      "sample-reasoning": {
        "pipeline-end": "Finalizing the pipeline after analysis."
      }
    },
    {
      "id": "pipeline-end",
      "model_id": "pipeline-end",
      "inputs_from_upstreams": [
        "various task outputs"
      ],
      "upstreams": [
        "gender-classification",
        "emotion-classification",
        "face-recognition",
        "cloth-color-classification",
        "human-pose-detection"
      ],
      "outputs_for_downstreams": [
        "none"
      ],
      "downstreams": [],
      "model-chosen-reason": "Pipeline-end task does not use any model as it serves as the endpoint for the pipeline.",
      "sample-reasoning": {}
    }
  ]
}